#!/usr/bin/env python3
"""
æµ‹è¯• Faster Whisper æœ¬åœ°è¯­éŸ³è½¬å½•
"""
import time
import os
from faster_whisper import WhisperModel

# æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
AUDIO_FILE = "/Users/lindadexiaoaojiao/Desktop/Builder/AIArchitect/æµ‹è¯•.m4a"

def test_faster_whisper(model_size="base", compute_type="int8"):
    """
    æµ‹è¯• Faster Whisper è½¬å½•
    
    Args:
        model_size: æ¨¡å‹å¤§å° (tiny, base, small, medium, large)
        compute_type: è®¡ç®—ç±»å‹ (int8, float16, float32)
    """
    print("=" * 60)
    print(f"æµ‹è¯• Faster Whisper - {model_size} æ¨¡å‹")
    print("=" * 60)
    print(f"éŸ³é¢‘æ–‡ä»¶: {AUDIO_FILE}")
    print(f"è®¡ç®—ç±»å‹: {compute_type}")
    print()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(AUDIO_FILE):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {AUDIO_FILE}")
        return
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    start_time = time.time()
    
    try:
        model = WhisperModel(
            model_size, 
            device="cpu",  # æˆ– "cuda" å¦‚æœæœ‰ GPU
            compute_type=compute_type
        )
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f} ç§’)")
        print()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return
    
    # è½¬å½•éŸ³é¢‘
    print("ğŸ¤ å¼€å§‹è½¬å½•...")
    transcribe_start = time.time()
    
    try:
        segments, info = model.transcribe(
            AUDIO_FILE, 
            language="zh",  # æŒ‡å®šä¸­æ–‡
            beam_size=5
        )
        
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬
        transcript_parts = []
        for segment in segments:
            transcript_parts.append(segment.text)
            print(f"  [{segment.start:.2f}s - {segment.end:.2f}s] {segment.text}")
        
        transcript = " ".join(transcript_parts)
        transcribe_time = time.time() - transcribe_start
        
        print()
        print("=" * 60)
        print("âœ… è½¬å½•å®Œæˆï¼")
        print("=" * 60)
        print(f"å®Œæ•´è½¬å½•: {transcript}")
        print()
        print(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {info.language} (æ¦‚ç‡: {info.language_probability:.2%})")
        print(f"è½¬å½•è€—æ—¶: {transcribe_time:.2f} ç§’")
        print(f"æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
        print()
        
        return transcript
        
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def test_different_models():
    """æµ‹è¯•ä¸åŒå¤§å°çš„æ¨¡å‹"""
    models_to_test = [
        ("base", "int8"),
        ("small", "int8"),
    ]
    
    results = {}
    
    for model_size, compute_type in models_to_test:
        print("\n" + "=" * 60)
        print(f"æµ‹è¯• {model_size} æ¨¡å‹ ({compute_type})")
        print("=" * 60)
        
        result = test_faster_whisper(model_size, compute_type)
        if result:
            results[model_size] = result
        
        print("\n" + "-" * 60 + "\n")
    
    # å¯¹æ¯”ç»“æœ
    if len(results) > 1:
        print("=" * 60)
        print("ğŸ“Š æ¨¡å‹å¯¹æ¯”")
        print("=" * 60)
        for model, transcript in results.items():
            print(f"\n{model} æ¨¡å‹:")
            print(f"  {transcript}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # æŒ‡å®šæ¨¡å‹å¤§å°
        model_size = sys.argv[1]
        compute_type = sys.argv[2] if len(sys.argv) > 2 else "int8"
        test_faster_whisper(model_size, compute_type)
    else:
        # æµ‹è¯•é»˜è®¤æ¨¡å‹
        print("ä½¿ç”¨é»˜è®¤é…ç½®æµ‹è¯• base æ¨¡å‹")
        print("ç”¨æ³•: python3 test_faster_whisper.py [model_size] [compute_type]")
        print("ç¤ºä¾‹: python3 test_faster_whisper.py small int8")
        print()
        test_faster_whisper("base", "int8")




